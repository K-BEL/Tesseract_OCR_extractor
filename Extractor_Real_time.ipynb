{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "import re\n",
    "\n",
    "import skimage.filters as filters\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import PIL.Image\n",
    "\n",
    "import os, random, pathlib, warnings, itertools, math, argparse, imutils\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'E:\\Programmes\\Tesseract-OCR\\tesseract.exe'\n",
    "tessdata_dir_config = r'E:\\Programmes\\Tesseract-OCR\\tesseract.exe\\tessdata' \n",
    "tessdata_dir_config1 = r'E:\\Programmes\\Tesseract-OCR\\tesseract.exe\\tessdata_fast' \n",
    "tessdata_dir_config2 = r'E:\\Programmes\\Tesseract-OCR\\tesseract.exe\\tessdata_best' \n",
    "custom_config0 = r'--oem 3 --psm 6'\n",
    "custom_config1 = r'--oem 3 --psm 11'\n",
    "custom_config2 = r'--oem 3 --psm 8'\n",
    "custom_config3 = r'--oem 1 --psm 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste = [tessdata_dir_config, tessdata_dir_config1, tessdata_dir_config2, custom_config0, custom_config1, custom_config2, custom_config3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_transform(image):  # in here you can do image filteration\n",
    "    image_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_grayscale_blurred = cv2.GaussianBlur(image_grayscale, (7,7), 0)\n",
    "    image_canny = cv2.Canny(image_grayscale_blurred, 10, 80)\n",
    "    _, mask = image_canny_inverted = cv2.threshold(image_canny, 30, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "def sketch_transform1(img):\n",
    "    mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    smooth = cv2.GaussianBlur(gray, (95,95), 0)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    division = cv2.divide(gray, smooth, scale=255)\n",
    "    sharp = filters.unsharp_mask(division, radius=1.5, amount=1.5, channel_axis=False, preserve_range=False)\n",
    "    sharp = (255*sharp).clip(0,255).astype(np.uint8)\n",
    "    thresh = cv2.threshold(sharp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    return thresh\n",
    "\n",
    "def tessdata(img, par):\n",
    "    #d = pytesseract.image_to_data(img)\n",
    "    d = pytesseract.image_to_data(img, lang='fra', config=par, output_type=Output.DICT) #thresh\n",
    "    return d\n",
    "\n",
    "def tessdata1(img, par):\n",
    "    text2 = pytesseract.image_to_string(img, lang='fra', config=par)  #mask or thresh \n",
    "    #print(text2) #thresh\n",
    "    #return text2\n",
    "    nums = re.findall(r'[A-Z][0-9][0-9][0-9][0-9][0-9][0-9].|[A-Z][0-9][0-9][0-9][0-9][0-9][0-9][0-9]', text2)\n",
    "    return nums\n",
    "\n",
    "def spacebar(list):\n",
    "    L = []\n",
    "    for i in list:\n",
    "        j = i.replace(' ','')\n",
    "        L.append(j)\n",
    "    return L\n",
    "\n",
    "def extraction(img1, img2, par1, par2):\n",
    "    d = tessdata(img1, par1)\n",
    "    #print(d)\n",
    "    nums = tessdata1(img2, par2)\n",
    "    L = spacebar(nums)\n",
    "    #print(L)\n",
    "    #f = L[0]\n",
    "    #text = None\n",
    "    #conf = 0\n",
    "    #M = 0,0,0,0\n",
    "    return d, L\n",
    "\n",
    "def box(img, conf, text, par):\n",
    "    x, y, w, h = par\n",
    "    text = \"\".join(text).strip()\n",
    "    cv2.rectangle(img,\n",
    "                (x, y),\n",
    "                (x + w, y + h),\n",
    "                (0, 0, 255), 2)\n",
    "    cv2.putText(img,\n",
    "                text,\n",
    "                (x, y - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.2, (0, 255, 255), 3)\n",
    "    cv2.imshow(\"test\", img)\n",
    "    k = cv2.waitKey(1)\n",
    "    return(\"Confidence: {}\".format(conf), \"Text: {}\".format(text))\n",
    "\n",
    "def Localise(img1, img2):\n",
    "    for a in liste:\n",
    "        for b in liste : \n",
    "            d, L = extraction(img1, img2,a,b)\n",
    "            print(L)\n",
    "            if L !=[] :\n",
    "                for i in range(0, len(d[\"text\"])):\n",
    "                    x = d[\"left\"][i]\n",
    "                    y = d[\"top\"][i]\n",
    "                    w = d[\"width\"][i]\n",
    "                    h = d[\"height\"][i]\n",
    "                    text = d[\"text\"][i]\n",
    "                    conf = int(float(d[\"conf\"][i]))\n",
    "                    M = x, y, w, h\n",
    "                    if str(L[0]) == str(text) and (conf is not None) and (text is not None) and (M is not None) :\n",
    "                        return (conf, text, M)                            \n",
    "                        break\n",
    "                    else :\n",
    "                        continue\n",
    "                    break\n",
    "            else :\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoCaptureObject = cv2.VideoCapture(0)\n",
    " \n",
    "upper_left = (50, 50)\n",
    "bottom_right = (500, 300)\n",
    "\n",
    "result = True\n",
    "while(result):\n",
    "    ret,image_frame = videoCaptureObject.read()\n",
    "\n",
    "    #Rectangle marker\n",
    "    r = cv2.rectangle(image_frame, upper_left, bottom_right, (100, 50, 200), 5)\n",
    "    rect_img = image_frame[upper_left[1] : bottom_right[1], upper_left[0] : bottom_right[0]]\n",
    "    \n",
    "    sketcher_rect = rect_img\n",
    "    \n",
    "    cv2.imshow(\"test\", image_frame)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('y'): #save on pressing 'y' \n",
    "        #sketcher_rect = sketch_transform1(sketcher_rect)\n",
    "        conf, text, M = Localise(sketcher_rect, sketcher_rect)\n",
    "        box(sketcher_rect, conf, text, M)\n",
    "        \n",
    "    \n",
    "    #Conversion for 3 channels to put back on original image (streaming)\n",
    "    #sketcher_rect_rgb = cv2.cvtColor(sketcher_rect, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    #Replacing the sketched image on Region of Interest\n",
    "    #image_frame[upper_left[1] : bottom_right[1], upper_left[0] : bottom_right[0]] = sketcher_rect\n",
    "    \n",
    "    \n",
    " \n",
    "videoCaptureObject.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
